{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957fcc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3635362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=GPT2Tokenizer.from_pretrained('gpt2-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ed4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad74bfc5ead4f64bfc6a2dfffb99294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model=TFGPT2LMHeadModel.from_pretrained('gpt2-large',pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5736aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae9a75",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2d63428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7454  612  373  257 2933]], shape=(1, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sentence='Once there was a boy'\n",
    "numeric_ids=tokenizer.encode(sentence,return_tensors='tf')\n",
    "print(numeric_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d11cedaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' was'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(numeric_ids[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "217fdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.generate(numeric_ids,max_length=100,num_beams=5,no_repeat_ngram_size=2,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63b2fbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
       "array([[ 7454,   612,   373,   257,  2933,   290,   257,  2576,    11,\n",
       "          290,   484,   547,   287,   262,   976,  2119,    11,   262,\n",
       "         2933,   531,   284,   262,  2576,    25,   366,    40,  1101,\n",
       "         1016,   284,  1494,   345,   526,   383,  2576,   531,    11,\n",
       "          366,  2949,    11,   314,   836,   470,   765,   284,  4656,\n",
       "           13,   314,   765,   345,   284,  2652,   351,   502,   526,\n",
       "          198,   198,   464,  2933,  1718,   257,  9845,   422,   465,\n",
       "        10000,   290, 21512,   607,    13,  1375,  3724,   287,   465,\n",
       "         5101,    13,   383,  2933,   373,  5169,   290,  5047,   351,\n",
       "          717,    12, 16863,  5123,    13,   679,   373, 11897,   284,\n",
       "         1204,   287,  3770,  1231,   262,  5885,   286, 25450,    13,\n",
       "        50256]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ebfd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a boy and a girl, and they were in the same room, the boy said to the girl: \"I'm going to kill you.\" The girl said, \"No, I don't want to die. I want you to stay with me.\"\n",
      "\n",
      "The boy took a knife from his pocket and stabbed her. She died in his arms. The boy was arrested and charged with first-degree murder. He was sentenced to life in prison without the possibility of parole.\n"
     ]
    }
   ],
   "source": [
    "output_text=tokenizer.decode(result[0],skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d1222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
